{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 9. PageRank with Map and Reduce in PySpark\n",
    "====\n",
    "### Mastering Large Datasets with Python by JT Wolohan \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elo ratings in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round5(x):\n",
    "  return 5*int(x/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_match(match):\n",
    "  ms = match.split(',')\n",
    "  match_data = {'winner': ms[10],\n",
    "                'loser': ms[20],\n",
    "                'surface': ms[2]}\n",
    "  return match_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elo_acc(acc,nxt):\n",
    "    w_elo = acc.get(nxt['winner'],1600)\n",
    "    l_elo = acc.get(nxt['loser'],1600)\n",
    "    Qw = 10**(w_elo/400)\n",
    "    Ql = 10**(l_elo/400)\n",
    "    Qt = Qw+Ql\n",
    "    acc[nxt['winner']] = round5(w_elo + 25*(1-(Qw/Qt)))\n",
    "    acc[nxt['loser']] = round5(l_elo - 25*(Ql/Qt))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elo_comb(a,b):\n",
    "    a.update(b)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Martina Hingis                1865\n",
      "Venus Williams                1830\n",
      "Monica Seles                  1765\n",
      "Serena Williams               1755\n",
      "Lindsay Davenport             1745\n",
      "Maria Sharapova               1720\n",
      "Petra Russegger               1710\n",
      "Akiko Morigami                1690\n",
      "Garbine Muguruza              1685\n",
      "Victoria Azarenka             1665\n",
      "Nour Abbes                    1660\n",
      "Timea Bacsinszky              1660\n",
      "Belinda Bencic                1655\n",
      "Amelie Mauresmo               1655\n",
      "Mary Pierce                   1655\n",
      "Jennifer Saret                1650\n",
      "Angelique Kerber              1650\n",
      "Bermet Duvanaeva              1650\n",
      "Svetlana Komleva              1650\n",
      "Cecilia Costa Melgar          1650\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(appName=\"TennisRatings\")\n",
    "text_files = sc.textFile(\"/path/to/my/data/wta_matches*\")\n",
    "xs = text_files.map(clean_match)\\\n",
    "             .aggregate({},elo_acc, elo_comb)\n",
    "\n",
    "for x in sorted(xs.items(), key=lambda x:x[1], reverse=True)[:20]:\n",
    "  print(\"{:<30}{}\".format(*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page rank in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2, ceil\n",
    "from functools import partial\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ceil5(x):\n",
    "    return ceil(x/5)*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_winner_loser(match):\n",
    "  ms = match.split(',')\n",
    "  # Put the loser in first position, winner in second\n",
    "  return (ms[20], ms[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_for_voting(losses):\n",
    "    return {'losses': losses,\n",
    "            'n_losses': len(losses),\n",
    "            'rating': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_ratings(d):\n",
    "  d['rating'] = 0\n",
    "  return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_points(acc, nxt):\n",
    "  k,v = nxt\n",
    "  boost = v['rating'] / (v['n_losses'] + .01)\n",
    "  for loss in v['losses']:\n",
    "    if loss not in acc.keys():\n",
    "      acc[loss] = {'losses':[], 'n_losses': 0}\n",
    "    opp_rating = acc.get(loss,{}).get('rating',0)\n",
    "    acc[loss]['rating'] = opp_rating + boost\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_scores(a, b):\n",
    "  for k,v in b.items():\n",
    "    try:\n",
    "      a[k]['rating'] = a[k]['rating'] + b[k]['rating']\n",
    "    except KeyError:\n",
    "      a[k] = v\n",
    "  return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the cell below, you may need to un-comment the Spark context. If you ran the Elo rating example above, leave it commented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serena Williams               12.4\t5475\n",
      "Venus Williams                12.0\t4230\n",
      "Kim Clijsters                 11.9\t3870\n",
      "Maria Sharapova               11.9\t3785\n",
      "Justine Henin                 11.8\t3660\n",
      "Elena Dementieva              11.6\t3130\n",
      "Amelie Mauresmo               11.6\t3115\n",
      "Svetlana Kuznetsova           11.6\t3060\n",
      "Jelena Jankovic               11.6\t3055\n",
      "Lindsay Davenport             11.6\t3055\n",
      "Victoria Azarenka             11.3\t2485\n",
      "Ana Ivanovic                  11.2\t2405\n",
      "Daniela Hantuchova            11.2\t2385\n",
      "Nadia Petrova                 11.2\t2360\n",
      "Caroline Wozniacki            11.2\t2350\n",
      "Agnieszka Radwanska           11.2\t2335\n",
      "Vera Zvonareva                11.2\t2320\n",
      "Patty Schnyder                11.1\t2220\n",
      "Samantha Stosur               11.1\t2215\n",
      "Francesca Schiavone           11.0\t2100\n"
     ]
    }
   ],
   "source": [
    "#sc = SparkContext(appName=\"TennisRatings\")\n",
    "match_data = sc.textFile(\"path/to/tennis/files\")\n",
    "xs = match_data.map(get_winner_loser)\\\n",
    "             .groupByKey()\\\n",
    "             .mapValues(initialize_for_voting)\n",
    "\n",
    "for i in range(8):\n",
    "    if i > 0:\n",
    "        xs = sc.parallelize(zs.items())\n",
    "    acc = dict(xs.mapValues(empty_ratings).collect())\n",
    "    zs = xs.aggregate(acc, allocate_points, combine_scores)\n",
    "\n",
    "ratings = [(k,v['rating']) for k,v in zs.items()]\n",
    "for player, rating in sorted(ratings, key=lambda x: x[1], reverse=True)[:20]:\n",
    "    print('{:<30}{}\\t{}'.format(player,\n",
    "                                round(log2(rating+1), 1),\n",
    "                                ceil5(rating)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Read for more? Go to chapter 10!](./Ch03_notebook.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldbook",
   "language": "python",
   "name": "mldbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
